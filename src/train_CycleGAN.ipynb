{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, cv2, torch, re\n",
    "sys.path.append(f\"{os.getcwd()}\")\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from style_transfer.networks import CycleGAN, CycleGANConfig\n",
    "from CycleGAN.data.unaligned_dataset import UnalignedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config = CycleGANConfig.create(\"style_transfer/config/cyclegan_train.yaml\", phase=\"train\")\n",
    "    \n",
    "    config.defrost()\n",
    "    config.checkpoints_dir = \"../../../Models/CycleGAN/checkpoints\"\n",
    "    config.dataroot = \"../../../Datasets/custom/ImpressionismStyleTrainingSmall\"\n",
    "    config.name = \"test_impressionism\"\n",
    "    config.display_freq = 1\n",
    "    config.print_freq = 1\n",
    "    config.batch_size = 1\n",
    "    config.num_threads = 1\n",
    "    config.serial_batches = False\n",
    "    config.save_no = 1\n",
    "    config.save_epoch_freq = 1\n",
    "    config.continue_train = True\n",
    "    config.display_server = \"http://localhost\"\n",
    "    config.display_env = \"test_impressionism\"\n",
    "    config.freeze()\n",
    "    print(config)\n",
    "    \n",
    "    dataset = UnalignedDataset(config)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=not config.serial_batches,\n",
    "        num_workers=int(config.num_threads),\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    network = CycleGAN(config)\n",
    "    network.train(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709ebb01-15a7-4c7d-bc50-093ca2082cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(path, direction=\"AtoB\"):\n",
    "    config = CycleGANConfig.create(\"style_transfer/config/cyclegan_test.yaml\", phase=\"test\")\n",
    "    \n",
    "    config.defrost()\n",
    "    config.results_dir = \"../.output/results\"   # saves results here.\n",
    "    config.num_threads = 0   # test code only supports num_threads = 0\n",
    "    config.batch_size = 1    # test code only supports batch_size = 1\n",
    "    config.serial_batches = True  # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "    config.no_flip = True    # no flip; comment this line if results on flipped images are needed.\n",
    "    config.display_id = -1   # no visdom display\n",
    "    config.freeze()\n",
    "    \n",
    "    network = CycleGAN(config)\n",
    "    network.loadModel({\n",
    "        \"G_A\": \"../../../Models/CycleGAN/baroque/latest_net_G_A.pth\",\n",
    "        \"G_B\": \"../../../Models/CycleGAN/baroque/latest_net_G_B.pth\"\n",
    "    })\n",
    "    with open(path, 'rb') as file:\n",
    "        image = Image.open(file)\n",
    "        image.convert(\"RGB\")\n",
    "    \n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Resize(256)(image)\n",
    "    image = transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = torch.stack((image,))\n",
    "    image = image.to(\"cuda\")\n",
    "\n",
    "    if direction == \"AtoB\":        \n",
    "        image = network.artisticToPhotographic(image)\n",
    "    elif direction == \"BtoA\":\n",
    "        image = network.photographicToArtistic(image)\n",
    "    \n",
    "    image = image[0] * 0.5 + 0.5\n",
    "    image = image.detach().cpu().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(config.results_dir, \"test_cyclegan.png\"), image * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beaed1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFromTrainToTestModel(loadPath, savePath):\n",
    "    state_dict = torch.load(loadPath)\n",
    "    if hasattr(state_dict, \"_metadata\"):\n",
    "        for meta_key in list(state_dict._metadata):\n",
    "            match = re.fullmatch(r\"model\\.[0-9]+\\.conv_block\\.([4-7])\", meta_key)\n",
    "            if match is not None:\n",
    "                block_idx = int(meta_key[match.regs[1][0]:match.regs[1][1]])\n",
    "                if not block_idx == 4:\n",
    "                    state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx-1}\"] = state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx}\"]\n",
    "                del state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx}\"]\n",
    "    for key in list(state_dict.keys()):\n",
    "        match = re.fullmatch(r\"model\\.[0-9]+\\.conv_block\\.([4-7])\\..+\", key)\n",
    "        if match is not None:\n",
    "            block_idx = int(key[match.regs[1][0]:match.regs[1][1]])\n",
    "            if not block_idx == 4:\n",
    "                state_dict[f\"{key[0:match.regs[1][0]]}{block_idx-1}{key[match.regs[1][1]:]}\"] = state_dict[f\"{key[0:match.regs[1][0]]}{block_idx}{key[match.regs[1][1]:]}\"]\n",
    "            del state_dict[f\"{key[0:match.regs[1][0]]}{block_idx}{key[match.regs[1][1]:]}\"]\n",
    "    torch.save(state_dict, savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cad5b97-7589-4fd8-90de-ea55cd9a778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ../../../Models/CycleGAN/checkpoints\n",
      "continue_train: True\n",
      "crop_size: 256\n",
      "dataroot: ../../../Datasets/custom/ImpressionismStyleTrainingSmall\n",
      "dataset_mode: unaligned\n",
      "direction: AtoB\n",
      "display_env: test_impressionism\n",
      "display_freq: 1\n",
      "display_id: 1\n",
      "display_ncols: 4\n",
      "display_port: 8097\n",
      "display_server: http://localhost\n",
      "display_winsize: 256\n",
      "epoch: latest\n",
      "epoch_count: 1\n",
      "gan_mode: lsgan\n",
      "gpu_ids: [0]\n",
      "init_gain: 0.02\n",
      "init_type: normal\n",
      "input_nc: 3\n",
      "isTrain: True\n",
      "lambda_A: 10.0\n",
      "lambda_B: 10.0\n",
      "lambda_identity: 0.5\n",
      "load_size: 286\n",
      "lr: 0.0002\n",
      "lr_decay_iters: 50\n",
      "lr_policy: linear\n",
      "max_dataset_size: inf\n",
      "model: train\n",
      "models_dir: checkpoints\n",
      "n_epochs: 100\n",
      "n_epochs_decay: 100\n",
      "n_layers_D: 3\n",
      "name: test_impressionism\n",
      "ndf: 64\n",
      "netD: basic\n",
      "netG: resnet_9blocks\n",
      "ngf: 64\n",
      "no_dropout: False\n",
      "no_flip: True\n",
      "norm: instance\n",
      "num_threads: 1\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 50\n",
      "preprocess: resize_and_crop\n",
      "print_freq: 1\n",
      "save_epoch_freq: 1\n",
      "save_no: 1\n",
      "serial_batches: False\n",
      "suffix: \n",
      "verbose: True\n",
      "initialize network with normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "The number of training images = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 1, time: 23.190, data: 2.694) D_A: 2.138 G_A: 2.855 cycle_A: 6.121 idt_A: 3.341 D_B: 1.587 G_B: 2.206 cycle_B: 6.690 idt_B: 3.044 \n",
      "(epoch: 1, iters: 2, time: 0.425, data: 0.001) D_A: 8.370 G_A: 1.812 cycle_A: 6.831 idt_A: 3.171 D_B: 1.962 G_B: 1.305 cycle_B: 6.468 idt_B: 3.339 \n",
      "saving the model at the end of epoch 1, iters 2\n",
      "End of epoch 1 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 1, time: 0.534, data: 2.948) D_A: 1.566 G_A: 1.521 cycle_A: 5.185 idt_A: 3.425 D_B: 6.210 G_B: 1.656 cycle_B: 6.836 idt_B: 2.543 \n",
      "(epoch: 2, iters: 2, time: 0.405, data: 0.000) D_A: 1.499 G_A: 1.278 cycle_A: 6.106 idt_A: 3.002 D_B: 1.959 G_B: 1.313 cycle_B: 6.232 idt_B: 2.982 \n",
      "saving the model at the end of epoch 2, iters 4\n",
      "End of epoch 2 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 1, time: 0.362, data: 3.263) D_A: 1.602 G_A: 1.649 cycle_A: 4.911 idt_A: 2.934 D_B: 6.584 G_B: 1.524 cycle_B: 6.081 idt_B: 2.364 \n",
      "(epoch: 3, iters: 2, time: 0.358, data: 0.001) D_A: 1.135 G_A: 1.355 cycle_A: 5.635 idt_A: 2.822 D_B: 4.748 G_B: 2.048 cycle_B: 5.795 idt_B: 2.730 \n",
      "saving the model at the end of epoch 3, iters 6\n",
      "End of epoch 3 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 1, time: 0.599, data: 3.102) D_A: 1.068 G_A: 1.346 cycle_A: 4.781 idt_A: 2.854 D_B: 1.354 G_B: 1.507 cycle_B: 5.663 idt_B: 2.320 \n",
      "(epoch: 4, iters: 2, time: 0.387, data: 0.000) D_A: 1.014 G_A: 1.341 cycle_A: 5.418 idt_A: 2.594 D_B: 2.425 G_B: 1.379 cycle_B: 5.369 idt_B: 2.661 \n",
      "saving the model at the end of epoch 4, iters 8\n",
      "End of epoch 4 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 1, time: 1.253, data: 2.544) D_A: 1.087 G_A: 1.322 cycle_A: 5.008 idt_A: 2.297 D_B: 1.007 G_B: 1.259 cycle_B: 4.753 idt_B: 2.452 \n",
      "(epoch: 5, iters: 2, time: 0.311, data: 0.001) D_A: 1.135 G_A: 1.430 cycle_A: 5.066 idt_A: 2.097 D_B: 0.864 G_B: 1.170 cycle_B: 4.350 idt_B: 2.466 \n",
      "saving the model at the end of epoch 5, iters 10\n",
      "End of epoch 5 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 1, time: 0.570, data: 2.227) D_A: 1.517 G_A: 2.090 cycle_A: 4.790 idt_A: 2.838 D_B: 0.797 G_B: 1.200 cycle_B: 6.284 idt_B: 2.307 \n",
      "(epoch: 6, iters: 2, time: 0.334, data: 0.001) D_A: 1.516 G_A: 1.638 cycle_A: 4.796 idt_A: 2.380 D_B: 1.059 G_B: 1.057 cycle_B: 5.404 idt_B: 2.323 \n",
      "saving the model at the end of epoch 6, iters 12\n",
      "End of epoch 6 / 200 \t Time Taken: 3 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# transform(\"../../../Datasets/custom/BaroqueStyleTraining/trainA/15_123_rembrandt_the-young-rembrandt-as-democritus-the-laughing-philosopher-1629.jpg\", \"AtoB\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_A.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_A.pth\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_B.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_B.pth\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     23\u001b[0m     dataset,\n\u001b[0;32m     24\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m     25\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mserial_batches,\n\u001b[0;32m     26\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_threads)\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m network \u001b[38;5;241m=\u001b[39m CycleGAN(config)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\src\\style_transfer\\networks\\CycleGAN.py:106\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    104\u001b[0m epoch_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m                  \u001b[38;5;66;03m# the number of training iterations in current epoch, reset to 0 every epoch\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate_learning_rate(epoch)    \u001b[38;5;66;03m# update learning rates in the beginning of every epoch.\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# inner loop within one epoch\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     iter_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# timer for computation per iteration\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m total_iters \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprint_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()\n",
    "# transform(\"../../../Datasets/custom/BaroqueStyleTraining/trainA/15_123_rembrandt_the-young-rembrandt-as-democritus-the-laughing-philosopher-1629.jpg\", \"AtoB\")\n",
    "# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_A.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_A.pth\")\n",
    "# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_B.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_B.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
