{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, cv2, torch, re\n",
    "sys.path.append(f\"{os.getcwd()}\")\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from style_transfer.networks import CycleGAN, CycleGANConfig\n",
    "from CycleGAN.data.unaligned_dataset import UnalignedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config = CycleGANConfig.create(\"style_transfer/config/cyclegan_train.yaml\", phase=\"train\")\n",
    "    \n",
    "    config.defrost()\n",
    "    config.checkpoints_dir = \"../../../Models/CycleGAN/checkpoints\"\n",
    "    config.dataroot = \"../../../Datasets/custom/BaroqueStyleTrainingSmall\"\n",
    "    config.name = \"test_baroque\"\n",
    "    config.display_freq = 1\n",
    "    config.print_freq = 1\n",
    "    config.batch_size = 1\n",
    "    config.num_threads = 1\n",
    "    config.serial_batches = False\n",
    "    config.save_no = 1\n",
    "    config.save_epoch_freq = 1\n",
    "    config.continue_train = True\n",
    "    config.display_server = \"http://localhost\"\n",
    "    config.display_env = \"test_baroque\"\n",
    "    config.freeze()\n",
    "    print(config)\n",
    "    \n",
    "    dataset = UnalignedDataset(config)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=not config.serial_batches,\n",
    "        num_workers=int(config.num_threads)\n",
    "    )\n",
    "    \n",
    "    network = CycleGAN(config)\n",
    "    network.train(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "709ebb01-15a7-4c7d-bc50-093ca2082cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(path, direction=\"AtoB\"):\n",
    "    config = CycleGANConfig.create(\"style_transfer/config/cyclegan_test.yaml\", phase=\"test\")\n",
    "    \n",
    "    config.defrost()\n",
    "    config.results_dir = \"../.output/results\"   # saves results here.\n",
    "    config.num_threads = 0   # test code only supports num_threads = 0\n",
    "    config.batch_size = 1    # test code only supports batch_size = 1\n",
    "    config.serial_batches = True  # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "    config.no_flip = True    # no flip; comment this line if results on flipped images are needed.\n",
    "    config.display_id = -1   # no visdom display\n",
    "    config.freeze()\n",
    "    \n",
    "    network = CycleGAN(config)\n",
    "    network.loadModel({\n",
    "        \"G_A\": \"../../../Models/CycleGAN/baroque/latest_net_G_A.pth\",\n",
    "        \"G_B\": \"../../../Models/CycleGAN/baroque/latest_net_G_B.pth\"\n",
    "    })\n",
    "    with open(path, 'rb') as file:\n",
    "        image = Image.open(file)\n",
    "        image.convert(\"RGB\")\n",
    "    \n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Resize(256)(image)\n",
    "    image = transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "    image = torch.stack((image,))\n",
    "    image = image.to(\"cuda\")\n",
    "\n",
    "    if direction == \"AtoB\":        \n",
    "        image = network.artisticToPhotographic(image)\n",
    "    elif direction == \"BtoA\":\n",
    "        image = network.photographicToArtistic(image)\n",
    "    \n",
    "    image = image[0] * 0.5 + 0.5\n",
    "    image = image.detach().cpu().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(config.results_dir, \"test_cyclegan.png\"), image * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "beaed1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFromTrainToTestModel(loadPath, savePath):\n",
    "    state_dict = torch.load(loadPath)\n",
    "    if hasattr(state_dict, \"_metadata\"):\n",
    "        for meta_key in list(state_dict._metadata):\n",
    "            match = re.fullmatch(r\"model\\.[0-9]+\\.conv_block\\.([4-7])\", meta_key)\n",
    "            if match is not None:\n",
    "                block_idx = int(meta_key[match.regs[1][0]:match.regs[1][1]])\n",
    "                if not block_idx == 4:\n",
    "                    state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx-1}\"] = state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx}\"]\n",
    "                del state_dict._metadata[f\"{meta_key[0:match.regs[1][0]]}{block_idx}\"]\n",
    "    for key in list(state_dict.keys()):\n",
    "        match = re.fullmatch(r\"model\\.[0-9]+\\.conv_block\\.([4-7])\\..+\", key)\n",
    "        if match is not None:\n",
    "            block_idx = int(key[match.regs[1][0]:match.regs[1][1]])\n",
    "            if not block_idx == 4:\n",
    "                state_dict[f\"{key[0:match.regs[1][0]]}{block_idx-1}{key[match.regs[1][1]:]}\"] = state_dict[f\"{key[0:match.regs[1][0]]}{block_idx}{key[match.regs[1][1]:]}\"]\n",
    "            del state_dict[f\"{key[0:match.regs[1][0]]}{block_idx}{key[match.regs[1][1]:]}\"]\n",
    "    torch.save(state_dict, savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cad5b97-7589-4fd8-90de-ea55cd9a778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ../../../Models/CycleGAN/checkpoints\n",
      "continue_train: True\n",
      "crop_size: 256\n",
      "dataroot: ../../../Datasets/custom/BaroqueStyleTrainingSmall\n",
      "dataset_mode: unaligned\n",
      "direction: AtoB\n",
      "display_env: test_baroque\n",
      "display_freq: 1\n",
      "display_id: 1\n",
      "display_ncols: 4\n",
      "display_port: 8097\n",
      "display_server: http://localhost\n",
      "display_winsize: 256\n",
      "epoch: latest\n",
      "epoch_count: 1\n",
      "gan_mode: lsgan\n",
      "gpu_ids: [0]\n",
      "init_gain: 0.02\n",
      "init_type: normal\n",
      "input_nc: 3\n",
      "isTrain: True\n",
      "lambda_A: 10.0\n",
      "lambda_B: 10.0\n",
      "lambda_identity: 0.5\n",
      "load_size: 286\n",
      "lr: 0.0002\n",
      "lr_decay_iters: 50\n",
      "lr_policy: linear\n",
      "max_dataset_size: inf\n",
      "model: train\n",
      "models_dir: checkpoints\n",
      "n_epochs: 100\n",
      "n_epochs_decay: 100\n",
      "n_layers_D: 3\n",
      "name: test_baroque\n",
      "ndf: 64\n",
      "netD: basic\n",
      "netG: resnet_9blocks\n",
      "ngf: 64\n",
      "no_dropout: False\n",
      "no_flip: True\n",
      "norm: instance\n",
      "num_threads: 1\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 50\n",
      "preprocess: resize_and_crop\n",
      "print_freq: 1\n",
      "save_epoch_freq: 1\n",
      "save_no: 1\n",
      "serial_batches: False\n",
      "suffix: \n",
      "verbose: True\n",
      "initialize network with normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "The number of training images = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tverh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\tverh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\src\\test_CycleGAN.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train()\n",
      "\u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\src\\test_CycleGAN.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mserial_batches,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(config\u001b[39m.\u001b[39mnum_threads)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m network \u001b[39m=\u001b[39m CycleGAN(config)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/UGent/Master%20Industriele%20Wetenschappen/Masterproef/Repositories/GANs_Pose_Estimation_on_Art_Collection/src/test_CycleGAN.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m network\u001b[39m.\u001b[39;49mtrain(dataloader)\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\src\\style_transfer\\networks\\CycleGAN.py:113\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    111\u001b[0m epoch_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_input(data)         \u001b[39m# unpack data from dataset and apply preprocessing\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49moptimize_parameters()   \u001b[39m# calculate loss functions, get gradients, update network weights\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m total_iters \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdisplay_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:   \u001b[39m# display images on visdom\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     visualizer\u001b[39m.\u001b[39mdisplay_current_results(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_current_visuals())\n",
      "File \u001b[1;32md:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\CycleGAN\\models\\cycle_gan_model.py:187\u001b[0m, in \u001b[0;36mCycleGANModel.optimize_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_requires_grad([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetD_A, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetD_B], \u001b[39mFalse\u001b[39;00m)  \u001b[39m# Ds require no gradients when optimizing Gs\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_G\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# set G_A and G_B's gradients to zero\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward_G()             \u001b[39m# calculate gradients for G_A and G_B\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_G\u001b[39m.\u001b[39mstep()       \u001b[39m# update G_A and G_B's weights\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m# D_A and D_B\u001b[39;00m\n",
      "File \u001b[1;32md:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\CycleGAN\\models\\cycle_gan_model.py:178\u001b[0m, in \u001b[0;36mCycleGANModel.backward_G\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m# combined loss and calculate gradients\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_G \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_G_A \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_G_B \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_cycle_A \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_cycle_B \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_idt_A \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_idt_B\n\u001b[1;32m--> 178\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_G\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[1;32mc:\\Users\\tverh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tverh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train()\n",
    "# transform(\"../../../Datasets/custom/BaroqueStyleTraining/trainA/15_123_rembrandt_the-young-rembrandt-as-democritus-the-laughing-philosopher-1629.jpg\", \"AtoB\")\n",
    "# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_A.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_A.pth\")\n",
    "# convertFromTrainToTestModel(\"../../../Models/CycleGAN/baroque/train/latest_net_G_B.pth\", \"../../../Models/CycleGAN/baroque/latest_net_G_B.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
