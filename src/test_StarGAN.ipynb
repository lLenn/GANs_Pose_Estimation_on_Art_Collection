{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7457bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING 1\n",
    "%env PYTORCH_CUDA_ALLOC_CONF max_split_size_mb:512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, cv2, torch\n",
    "sys.path.append(f\"{os.getcwd()}\")\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from style_transfer.networks import StarGAN, StarGANConfig\n",
    "from StarGAN.core.data_loader import get_train_loader, get_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709ebb01-15a7-4c7d-bc50-093ca2082cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config = StarGANConfig.create(\"style_transfer/config/stargan.yaml\")\n",
    "    # Dataset\n",
    "    config.defrost()\n",
    "    config.train_img_dir = \"../../../Datasets/custom/StarGANTrainingSmall/train\"\n",
    "    config.val_img_dir = \"../../../Datasets/custom/StarGANTrainingSmall/val\"\n",
    "    config.src_dir = \"../../../Datasets/custom/StarGANTrainingSmall\"\n",
    "    config.checkpoint_dir = \"../../../Models/stargan\"\n",
    "    config.result_dir = \".output/results\"\n",
    "    config.eval_dir = \".output/results\"\n",
    "    config.num_domains = 4\n",
    "    # Training\n",
    "    config.mode = \"train\"\n",
    "    config.num_workers = 4\n",
    "    config.total_iters = 5\n",
    "    config.batch_size = 1\n",
    "    config.print_every = 1\n",
    "    config.sample_every = 1\n",
    "    config.save_every = 1\n",
    "    config.eval_every = 10000\n",
    "    \n",
    "    # Visdom\n",
    "    config.name = \"test_stargan\"\n",
    "    config.display_server = \"http://localhost\"\n",
    "    config.display_port = 8097\n",
    "    config.display_env = \"test_stargan\"\n",
    "    config.freeze()\n",
    "    \n",
    "    network = StarGAN(config)\n",
    "    network.train(\n",
    "        dataloader_src=get_train_loader(\n",
    "            root=config.train_img_dir,\n",
    "            which='source',\n",
    "            img_size=config.img_size,\n",
    "            batch_size=config.batch_size,\n",
    "            prob=config.randcrop_prob,\n",
    "            num_workers=config.num_workers),\n",
    "        dataloader_ref=get_train_loader(\n",
    "            root=config.train_img_dir,\n",
    "            which='reference',\n",
    "            img_size=config.img_size,\n",
    "            batch_size=config.batch_size,\n",
    "            prob=config.randcrop_prob,\n",
    "            num_workers=config.num_workers),\n",
    "        dataloader_val=get_test_loader(\n",
    "            root=config.val_img_dir,\n",
    "            img_size=config.img_size,\n",
    "            batch_size=config.val_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=config.num_workers)\n",
    "    )\n",
    "\n",
    "    print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(imagePath, direction=\"AtoB\"):\n",
    "    config = StarGANConfig.create(\"style_transfer/config/stargan.yaml\")\n",
    "    network = StarGAN(config)\n",
    "    network.loadModel(\"../../../Models/afhq\", 100000)\n",
    "    with open(imagePath, 'rb') as file:\n",
    "        image = Image.open(file)\n",
    "        image.convert(\"RGB\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    image = torch.stack((transform(image),)).to(\"cuda\")\n",
    "\n",
    "    if direction == \"AtoB\":\n",
    "        style = torch.tensor([1]).to(\"cuda\")\n",
    "        image = network.imageToStyle(image, style)\n",
    "    elif direction == \"BtoA\":\n",
    "        style = torch.tensor([0]).to(\"cuda\")\n",
    "        image = network.imageToStyle(image, style)\n",
    "    \n",
    "    image = image[0] * 0.5 + 0.5\n",
    "    image = image.detach().cpu().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(\"../.output/results/\", \"test_StarGAN.png\"), image * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cad5b97-7589-4fd8-90de-ea55cd9a778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of generator: 33892995\n",
      "Number of parameters of mapping_network: 4079872\n",
      "Number of parameters of style_encoder: 20982592\n",
      "Number of parameters of discriminator: 20853316\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader to fetch source images during the training phase...\n",
      "Preparing DataLoader to fetch reference images during the training phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Start training...\n",
      "(iters: 1, time: 7.396) D/latent_real: 0.518 D/latent_fake: 0.205 D/latent_reg: 0.001 D/ref_real: 0.000 D/ref_fake: 0.000 D/ref_reg: 0.005 G/latent_adv: 18.522 G/latent_sty: 1.773 G/latent_ds: 0.836 G/latent_cyc: 0.814 G/ref_adv: 11.995 G/ref_sty: 0.898 G/ref_ds: 0.646 G/ref_cyc: 0.779 G/lambda_ds: 1.000 \n",
      "(iters: 2, time: 10.180) D/latent_real: 1.139 D/latent_fake: 1.786 D/latent_reg: 0.001 D/ref_real: 0.000 D/ref_fake: 0.000 D/ref_reg: 0.010 G/latent_adv: 27.458 G/latent_sty: 1.274 G/latent_ds: 0.841 G/latent_cyc: 0.849 G/ref_adv: 19.728 G/ref_sty: 0.692 G/ref_ds: 0.513 G/ref_cyc: 0.837 G/lambda_ds: 1.000 \n",
      "(iters: 3, time: 12.831) D/latent_real: 0.000 D/latent_fake: 18.045 D/latent_reg: 0.003 D/ref_real: 0.086 D/ref_fake: 0.000 D/ref_reg: 0.001 G/latent_adv: 14.221 G/latent_sty: 1.190 G/latent_ds: 0.774 G/latent_cyc: 0.737 G/ref_adv: 11.720 G/ref_sty: 0.857 G/ref_ds: 0.706 G/ref_cyc: 0.722 G/lambda_ds: 1.000 \n",
      "(iters: 4, time: 15.464) D/latent_real: 0.016 D/latent_fake: 6.819 D/latent_reg: 0.001 D/ref_real: 2.569 D/ref_fake: 0.000 D/ref_reg: 0.001 G/latent_adv: 4.255 G/latent_sty: 1.230 G/latent_ds: 0.724 G/latent_cyc: 0.715 G/ref_adv: 0.026 G/ref_sty: 0.629 G/ref_ds: 0.690 G/ref_cyc: 0.727 G/lambda_ds: 1.000 \n",
      "(iters: 5, time: 18.079) D/latent_real: 5.483 D/latent_fake: 3.117 D/latent_reg: 0.001 D/ref_real: 0.003 D/ref_fake: 0.000 D/ref_reg: 0.001 G/latent_adv: 13.461 G/latent_sty: 1.053 G/latent_ds: 0.809 G/latent_cyc: 0.842 G/ref_adv: 4.921 G/ref_sty: 0.787 G/ref_ds: 0.534 G/ref_cyc: 0.906 G/lambda_ds: 1.000 \n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "# transform(\"../.output/results/test_StarGAN copy 2.png\", \"BtoA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
