{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesToGroup = \"../../../Datasets/human-art/images/real_human/drama\"\n",
    "folderToGroupIn = \"../../../Datasets/custom/Drama/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 936/2000 [01:09<01:18, 13.49it/s]\n",
      "100%|██████████| 2000/2000 [02:19<00:00, 14.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "featureExtractor = vgg19(weights=VGG19_Weights.DEFAULT) # VGG\n",
    "featureExtractor.eval() # VGG\n",
    "'''\n",
    "featureExtractor = YOLO('yolov8n.pt') # YOLOv8\n",
    "'''\n",
    "featureExtractor.to(\"cuda\")\n",
    "\n",
    "features = np.empty((0, 1000))\n",
    "dir = os.listdir(imagesToGroup)\n",
    "processedFiles = []\n",
    "pbar = tqdm(total=len(dir))\n",
    "for file in dir:\n",
    "    path = os.path.join(imagesToGroup, file)\n",
    "    if os.path.isfile(path):\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if image is None:\n",
    "            pbar.update()\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(224), \n",
    "            transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]) # VGG\n",
    "        image = transform(image) # VGG\n",
    "        '''\n",
    "        image = cv2.resize(image, (640, 640)) # YOLOv8\n",
    "        image = image / 255 # YOLOv8\n",
    "        image = transforms.ToTensor()(image) # YOLOv8\n",
    "        '''\n",
    "        image = image.to(\"cuda\")\n",
    "        image = torch.stack((image,))\n",
    "        imageFeatures = featureExtractor(image) # VGG\n",
    "        # imageFeatures = featureExtractor.predict(source=image) # YOLOv8\n",
    "        features = np.append(features, imageFeatures.detach().cpu().numpy(), axis=0)\n",
    "        processedFiles.append(file)\n",
    "    \n",
    "    pbar.update()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 43/49 [00:21<00:03,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0.5\n",
    "step = 0.01\n",
    "featuresToGroup = features\n",
    "filesToGroup = processedFiles\n",
    "pbar = tqdm(total=int(i/step)-1)\n",
    "while i >= step and len(filesToGroup) > 0:\n",
    "    group0Files = []\n",
    "    group0Features = np.empty((0, 1000))\n",
    "    groups = DBSCAN(eps=i, metric=\"cosine\").fit(featuresToGroup)\n",
    "    countOrphans = np.count_nonzero(groups.labels_ == -1)\n",
    "    if countOrphans/len(filesToGroup) < 0.05:\n",
    "        i -= step\n",
    "        pbar.update()\n",
    "        continue\n",
    "    for index, file in enumerate(filesToGroup):\n",
    "        group = int(groups.labels_[index])\n",
    "        groupLabel = f\"{int(i*100)}_{group}\" if group != -1 else \"orphans\"\n",
    "        if group != 0 or step >= i-step:\n",
    "            sourcePath = os.path.join(imagesToGroup, file)\n",
    "            targetFolder = os.path.join(folderToGroupIn, groupLabel)\n",
    "            targetPath = os.path.join(folderToGroupIn, groupLabel, file)\n",
    "            if not os.path.exists(targetFolder):\n",
    "                os.makedirs(targetFolder)\n",
    "            shutil.copy(sourcePath, targetPath)\n",
    "        elif group == 0:\n",
    "            group0Files.append(file)\n",
    "            group0Features = np.append(group0Features, [featuresToGroup[index]], axis=0)\n",
    "    filesToGroup = group0Files\n",
    "    featuresToGroup = group0Features\n",
    "    i -= step\n",
    "    pbar.update()\n",
    "pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
