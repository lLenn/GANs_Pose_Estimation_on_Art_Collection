{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "configPath = \"metric_learning/config/cirtorch.yaml\"\n",
    "modelPath = \"../../../Models/CIBR/rSfM120k-tl-resnet152-gem-w-f39cada.pth\"\n",
    "imageDatabasePath = \"../../../Datasets/wikiart/High_Renaissance\"\n",
    "queryImagePath = \"../../../Datasets/custom/15_19_titian_venus-anadyomene.jpg\"\n",
    "folderToStoreResultsPath = \"../../../Datasets/custom/RenaissanceCirtorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\genericdataset.py\", line 51, in __getitem__\n    img = self.loader(path)\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\datahelpers.py\", line 40, in default_loader\n    return pil_loader(path)\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\datahelpers.py\", line 23, in pil_loader\n    with open(path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '../../../Datasets/custom/15_19_titian_venus-anadyomene.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     cirtorchNetwork\u001b[38;5;241m.\u001b[39mcreateDatabase(databaseImages)\n\u001b[0;32m     19\u001b[0m     cirtorchNetwork\u001b[38;5;241m.\u001b[39msaveDatabase(databasePath)\n\u001b[1;32m---> 20\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcirtorchNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueryImagePath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m scoresPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folderToStoreResultsPath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(scoresPath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m scoresFile:\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\src\\metric_learning\\networks\\CirTorch.py:69\u001b[0m, in \u001b[0;36mCirTorch.query\u001b[1;34m(self, queryImages)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 69\u001b[0m queryVectors \u001b[38;5;241m=\u001b[39m \u001b[43mextract_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueryImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m queryVectors \u001b[38;5;241m=\u001b[39m queryVectors\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     71\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mT, queryVectors)\n",
      "File \u001b[1;32md:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\networks\\imageretrievalnet.py:292\u001b[0m, in \u001b[0;36mextract_vectors\u001b[1;34m(net, images, image_size, transform, bbxs, ms, msp, print_freq)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    291\u001b[0m     vecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(net\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputdim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlen\u001b[39m(images))\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\UGent\\Master Industriele Wetenschappen\\Masterproef\\Repositories\\GANs_Pose_Estimation_on_Art_Collection\\.venv_win\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\genericdataset.py\", line 51, in __getitem__\n    img = self.loader(path)\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\datahelpers.py\", line 40, in default_loader\n    return pil_loader(path)\n  File \"d:\\ugent\\master industriele wetenschappen\\masterproef\\repositories\\gans_pose_estimation_on_art_collection\\lib\\cirtorch\\cirtorch\\datasets\\datahelpers.py\", line 23, in pil_loader\n    with open(path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '../../../Datasets/custom/15_19_titian_venus-anadyomene.jpg'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from metric_learning.networks import CirTorch, CirTorchConfig\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "config = CirTorchConfig.create(configPath)\n",
    "config.defrost()\n",
    "config.model = modelPath\n",
    "config.freeze()\n",
    "cirtorchNetwork = CirTorch(config)\n",
    "cirtorchNetwork.load()\n",
    "databasePath = os.path.join(folderToStoreResultsPath, \"database.pkl\")\n",
    "if os.path.exists(databasePath):\n",
    "    cirtorchNetwork.loadDatabase(databasePath)\n",
    "else:\n",
    "    databaseImages = [os.path.join(imageDatabasePath, file) for file in os.listdir(imageDatabasePath)]\n",
    "    cirtorchNetwork.createDatabase(databaseImages)\n",
    "    cirtorchNetwork.saveDatabase(databasePath)\n",
    "scores = cirtorchNetwork.query(queryImagePath)\n",
    "\n",
    "scoresPath = os.path.join(folderToStoreResultsPath, \"scores.pkl\")\n",
    "with open(scoresPath, 'wb') as scoresFile:\n",
    "    pickle.dump(scores, scoresFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "scoresPath = os.path.join(folderToStoreResultsPath, \"scores.pkl\")\n",
    "with open(scoresPath, 'rb') as scoresFile:\n",
    "    scores = pickle.load(scoresFile)\n",
    "prevScore = 100\n",
    "countSameScore = 0\n",
    "for score in scores:\n",
    "    if score[1] > 0.15:\n",
    "        scoreAsInteger = int(score[1]*100)\n",
    "        if prevScore != scoreAsInteger:\n",
    "            countSameScore = 1\n",
    "        else:\n",
    "            countSameScore += 1\n",
    "        prevScore = scoreAsInteger\n",
    "        imagePath = cirtorchNetwork.images[int(score[0])]\n",
    "        shutil.copy(imagePath, os.path.join(folderToStoreResultsPath, f\"{scoreAsInteger}_{countSameScore}_{os.path.split(imagePath)[-1]}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
